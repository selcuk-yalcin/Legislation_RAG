# ğŸ§ª RAGAS Evaluation Framework

**RAGAS** (RAG Assessment) kÃ¼tÃ¼phanesi kullanÄ±larak Legislation RAG sisteminin kalitesi periyodik olarak Ã¶lÃ§Ã¼lÃ¼r.

## ğŸ“Š Ã–lÃ§Ã¼len Metrikler

### 1. **Faithfulness (Sadakat)** 
- **Ne Ã¶lÃ§er?** CevabÄ±n kaynak dÃ¶kÃ¼manlara ne kadar sadÄ±k olduÄŸu
- **Neden Ã¶nemli?** Hallucination (uydurma) tespiti iÃ§in kritik
- **Hedef:** â‰¥ 0.8

### 2. **Answer Relevancy (Ä°lgililik)**
- **Ne Ã¶lÃ§er?** CevabÄ±n soruyla ne kadar ilgili olduÄŸu
- **Neden Ã¶nemli?** KullanÄ±cÄ± memnuniyeti ve doÄŸruluk
- **Hedef:** â‰¥ 0.7

### 3. **Context Precision (Hassasiyet)**
- **Ne Ã¶lÃ§er?** Retrieval sisteminin doÄŸru dÃ¶kÃ¼manlarÄ± bulma yeteneÄŸi
- **Neden Ã¶nemli?** YanlÄ±ÅŸ bilgi Ã¶nleme
- **Hedef:** â‰¥ 0.7

### 4. **Context Recall (HatÄ±rlama)**
- **Ne Ã¶lÃ§er?** TÃ¼m ilgili bilginin bulunup bulunmadÄ±ÄŸÄ±
- **Neden Ã¶nemli?** Eksik bilgi Ã¶nleme
- **Hedef:** â‰¥ 0.7

### 5. **Context Relevancy (BaÄŸlam Ä°lgililikliliÄŸi)**
- **Ne Ã¶lÃ§er?** BaÄŸlamÄ±n soruyla ne kadar ilgili olduÄŸu
- **Neden Ã¶nemli?** Gereksiz bilgi filtrasyonu
- **Hedef:** â‰¥ 0.7

## ğŸš€ KullanÄ±m

### Kurulum

```bash
# RAGAS ve baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼kle
pip install ragas datasets

# Veya tÃ¼m requirements'Ä± yÃ¼kle
pip install -r requirements.txt
```

### Evaluation Ã‡alÄ±ÅŸtÄ±rma

```bash
# Basit kullanÄ±m
python ragas_evaluation.py

# Ã‡Ä±ktÄ±: evaluation_results/ragas_evaluation_YYYYMMDD_HHMMSS.json
```

### Ã–rnek Ã‡Ä±ktÄ±

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    RAGAS EVALUATION SYSTEM                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ RAG sistemini baÅŸlatÄ±yorum...
âœ… RAG sistemi hazÄ±r!

ğŸ“ Test dataset'i hazÄ±rlanÄ±yor...
âœ… 5 test sorusu hazÄ±r

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§ª RAGAS Evaluation BaÅŸlÄ±yor
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ 5 test sorusu iÅŸleniyor...

[1/5] Soru: Ä°ÅŸverenin iÅŸ saÄŸlÄ±ÄŸÄ± ve gÃ¼venliÄŸi konusundaki yÃ¼kÃ¼mlÃ¼lÃ¼...
    âœ“ Cevap alÄ±ndÄ± (1234 karakter)
    âœ“ Context: 5 dÃ¶kÃ¼man

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š RAGAS Metrikleri HesaplanÄ±yor...
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š RAGAS EVALUATION RAPORU
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ Metrik SkorlarÄ± (0-1 arasÄ±, 1 en iyi):

Faithfulness (Sadakat)                  : 0.872 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ ğŸŸ¢ MÃ¼kemmel
Answer Relevancy (Ä°lgililik)            : 0.765 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ ğŸŸ¡ Ä°yi
Context Precision (Hassasiyet)          : 0.691 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ ğŸŸ¡ Ä°yi
Context Recall (HatÄ±rlama)              : 0.723 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ ğŸŸ¡ Ä°yi
Context Relevancy (BaÄŸlam Ä°lgililk...)  : 0.804 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ ğŸŸ¢ MÃ¼kemmel

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GENEL ORTALAMA                          : 0.771
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ’¾ SonuÃ§lar kaydedildi: evaluation_results/ragas_evaluation_20250112_143022.json

âœ… Evaluation tamamlandÄ±!
```

## ğŸ“ Ã‡Ä±ktÄ± DosyasÄ± FormatÄ±

```json
{
  "timestamp": "20250112_143022",
  "date": "2025-01-12T14:30:22.123456",
  "num_test_cases": 5,
  "metrics": {
    "faithfulness": 0.872,
    "answer_relevancy": 0.765,
    "context_precision": 0.691,
    "context_recall": 0.723,
    "context_relevancy": 0.804
  },
  "test_cases": [
    {
      "question": "Ä°ÅŸverenin iÅŸ saÄŸlÄ±ÄŸÄ± ve gÃ¼venliÄŸi konusundaki...",
      "ground_truth": "Ä°ÅŸveren, Ã§alÄ±ÅŸanlarÄ±n iÅŸ saÄŸlÄ±ÄŸÄ± ve gÃ¼venliÄŸini..."
    }
  ]
}
```

## ğŸ¯ Skor Yorumlama

| Skor AralÄ±ÄŸÄ± | Rating | Durum | Aksiyon |
|--------------|--------|-------|---------|
| 0.8 - 1.0 | ğŸŸ¢ MÃ¼kemmel | Sistem iyi Ã§alÄ±ÅŸÄ±yor | SÃ¼rdÃ¼r |
| 0.6 - 0.8 | ğŸŸ¡ Ä°yi | Kabul edilebilir | Ä°zle |
| 0.4 - 0.6 | ğŸŸ  Orta | Ä°yileÅŸtirme gerekli | Optimize et |
| 0.0 - 0.4 | ğŸ”´ DÃ¼ÅŸÃ¼k | Ciddi sorun var | Acil mÃ¼dahale |

## ğŸ”§ Ä°yileÅŸtirme Ã–nerileri

### Faithfulness DÃ¼ÅŸÃ¼kse (< 0.7)
**Sorun:** LLM uydurma yapÄ±yor, kaynaklara sadÄ±k kalmÄ±yor

**Ã‡Ã¶zÃ¼mler:**
```python
# config.py - Prompt'u gÃ¼Ã§lendir
SYSTEM_PROMPT = """
Sen bir mevzuat asistanÄ±sÄ±n.
SADECE verilen kaynaklardaki bilgileri kullan.
Kaynaklarda olmayan bilgi verme.
Emin deÄŸilsen 'Bu bilgi kaynaklarda yok' de.
"""

# rag_pipeline.py - Temperature dÃ¼ÅŸÃ¼r
temperature=0.2  # Daha deterministik
```

### Answer Relevancy DÃ¼ÅŸÃ¼kse (< 0.7)
**Sorun:** Cevaplar konudan sapÄ±yor

**Ã‡Ã¶zÃ¼mler:**
```python
# query_expansion.py - Daha odaklÄ± expansion
EXPANSION_PROMPT = """
Soruyu SADECE yasal terimlerle geniÅŸlet.
Konudan sapma.
"""

# config.py - Query expansion'Ä± azalt
MAX_EXPANDED_QUERIES = 2  # 3'ten dÃ¼ÅŸÃ¼r
```

### Context Precision DÃ¼ÅŸÃ¼kse (< 0.7)
**Sorun:** YanlÄ±ÅŸ dÃ¶kÃ¼manlar alÄ±nÄ±yor

**Ã‡Ã¶zÃ¼mler:**
```python
# config.py - Reranking gÃ¼Ã§lendir
FINAL_TOP_K = 3  # Daha az ama daha doÄŸru
RERANK_SCORE_THRESHOLD = 0.5  # EÅŸiÄŸi yÃ¼kselt

# mongodb_vector_store.py - Similarity threshold ekle
if score < 0.7:  # DÃ¼ÅŸÃ¼k skorlu dÃ¶kÃ¼manlarÄ± filtrele
    continue
```

### Context Recall DÃ¼ÅŸÃ¼kse (< 0.7)
**Sorun:** Ä°lgili bilgiler kaÃ§Ä±rÄ±lÄ±yor

**Ã‡Ã¶zÃ¼mler:**
```python
# config.py - Daha fazla dÃ¶kÃ¼man al
INITIAL_RETRIEVAL_K = 100  # 50'den artÄ±r

# mongodb_vector_store.py - numCandidates artÄ±r
"numCandidates": k * 20  # 10'dan artÄ±r
```

## ğŸ“… Periyodik Evaluation

### Manuel Ã‡alÄ±ÅŸtÄ±rma
```bash
# Her deployment Ã¶ncesi
python ragas_evaluation.py

# SonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±r
ls -lh evaluation_results/
```

### Otomatik Ã‡alÄ±ÅŸtÄ±rma (Ä°steÄŸe BaÄŸlÄ±)

**Cron Job (Her hafta)**
```bash
# crontab -e
0 9 * * 1 cd /path/to/Legislation_RAG && python ragas_evaluation.py
```

**CI/CD Pipeline (Her deployment)**
```yaml
# .github/workflows/deploy.yml
- name: Run RAGAS Evaluation
  run: |
    python ragas_evaluation.py
    # SonuÃ§larÄ± Slack'e gÃ¶nder
```

**Flask Endpoint (API ile)**
```python
# app.py
@app.route('/api/evaluate', methods=['POST'])
def run_evaluation():
    # Admin auth required
    evaluator = RAGEvaluator()
    results = evaluator.run_evaluation()
    return jsonify(results)
```

## ğŸ§ª Test Dataset GeniÅŸletme

```python
# ragas_evaluation.py - create_test_dataset()

# Daha fazla test sorusu ekle
test_cases = [
    {
        "question": "Yeni soru buraya...",
        "ground_truth": "Beklenen cevap buraya..."
    },
    # ... 50+ soru olana kadar ekle
]

# GerÃ§ek kullanÄ±cÄ± sorularÄ±ndan oluÅŸtur
# app.py'de log'lanan sorularÄ± kullan
```

## ğŸ“ˆ SonuÃ§larÄ± Ä°zleme

```python
import json
import glob
import matplotlib.pyplot as plt

# TÃ¼m evaluation sonuÃ§larÄ±nÄ± oku
results = []
for file in sorted(glob.glob("evaluation_results/*.json")):
    with open(file) as f:
        results.append(json.load(f))

# Zaman iÃ§inde metrik trendlerini gÃ¶rselleÅŸtir
dates = [r['date'] for r in results]
faithfulness = [r['metrics']['faithfulness'] for r in results]

plt.plot(dates, faithfulness, label='Faithfulness')
plt.axhline(y=0.8, color='r', linestyle='--', label='Target')
plt.legend()
plt.show()
```

## âš ï¸ Dikkat Edilecekler

1. **OpenRouter API KullanÄ±mÄ±**: Her evaluation OpenRouter API call yapar (maliyet)
2. **MongoDB BaÄŸlantÄ±**: Vector Search Index aktif olmalÄ±
3. **Test Dataset**: Ground truth'larÄ± iyi tanÄ±mla
4. **SonuÃ§ Yorumlama**: Tek baÅŸÄ±na skor yetmez, trendlere bak

## ğŸ“ Kaynaklar

- [RAGAS Documentation](https://docs.ragas.io/)
- [RAGAS Metrics Explained](https://docs.ragas.io/en/latest/concepts/metrics/index.html)
- [RAG Evaluation Best Practices](https://www.rungalileo.io/blog/mastering-rag-evaluation)

---

**Sonraki AdÄ±m:** `python ragas_evaluation.py` Ã§alÄ±ÅŸtÄ±r ve sistemin kalitesini Ã¶lÃ§! ğŸš€
